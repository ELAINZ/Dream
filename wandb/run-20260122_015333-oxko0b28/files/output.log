Total training steps: 699
Epoch 1/3:   0%|                                                                                                                               | 0/233 [00:00<?, ?it/s]
DEBUG: shift logits: tensor([[-2.7500, -4.2188, -5.8438,  ...,  0.7617,  0.7617,  0.7617],
        [-2.7500, -4.2188, -5.8438,  ...,  0.7617,  0.7617,  0.7617],
        [-0.2832, -3.0000, -5.2500,  ...,  0.7188,  0.7188,  0.7188],
        ...,
        [-0.8125, -6.0625, -6.9375,  ...,  0.3027,  0.3027,  0.3027],
        [-0.7734, -5.6875, -7.0625,  ..., -0.2832, -0.2832, -0.2832],
        [-1.3672, -6.3125, -5.5625,  ...,  1.5859,  1.5859,  1.5859]],
       device='cuda:0', dtype=torch.bfloat16, grad_fn=<ViewBackward0>) shift_labels: tensor([151644,    872,    198,     38,  24380,   6801,    311,   3695,    264,
         13041,   4349,    429,   7049,    220,     17,  27418,   2667,  14462,
            13,  54257,    702,    220,     20,     19,   3041,  57074,     11,
           323,   1052,    525,    220,     21], device='cuda:0')
DEBUG: loss: tensor([11.1875, 17.1250,  4.8125, 11.0000,  8.5000, 12.1250, 12.0000, 21.7500,
         9.1250, 14.2500, 10.8750, 13.8750, 14.3125,  6.8750, 11.5625, 12.3750,
        14.5625,  5.9062,  0.8125,  9.0000, 11.5000,  0.9961,  3.4531,  6.6250,
        14.0000, 15.6250,  3.8750,  4.3750,  5.5312, 10.4375,  0.2812,  7.6875],
       device='cuda:0', grad_fn=<NllLossBackward0>)
loss mask: tensor([False, False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False, False,
        False, False, False, False, False, False, False, False, False, False,
        False, False], device='cuda:0') loss: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<MaskedFillBackward0>)
weight: tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
         0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0',
       dtype=torch.bfloat16)
DEBUG loss: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       grad_fn=<MulBackward0>)
